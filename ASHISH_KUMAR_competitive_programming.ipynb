{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashishmission93/ML-PTOJECTS/blob/main/ASHISH_KUMAR_competitive_programming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ASHISH_KUMAR\n"
      ],
      "metadata": {
        "id": "LufK-Kso0uRO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment Requirements:\n",
        "\n",
        "Convolution Function:\n",
        "\n",
        "Accepts an image, a filter kernel, stride, padding, and an activation function.\n",
        "Performs convolution on the input image using the kernel, considering stride and padding.\n",
        "Applies the specified non-linearity (activation function).\n",
        "Displays the input image, filter kernel, and the output activation map.\n",
        "Should handle multi-channel input and a corresponding kernel volume.\n",
        "Pooling Function:\n",
        "\n",
        "Accepts the activation map from a convolutional layer, a pooling function, and a stride.\n",
        "Performs pooling on the activation map.\n",
        "Displays the input activation map and the pooled output.\n",
        "Convolution Layer Function:\n",
        "\n",
        "Accepts a volume (image or activation maps), filter kernels, stride, padding, and an activation function.\n",
        "Convolves the input volume with each of the kernels.\n",
        "Generates an output activation volume after applying the specified non-linearity.\n",
        "Displays the input volume, filter kernels, and the output activation maps.\n",
        "Pooling Layer Function:\n",
        "\n",
        "Accepts the activation map volume, pooling function, and stride.\n",
        "Generates a pooled output volume.\n",
        "Displays the input and output volumes.\n",
        "Flattening (Unraveling) Function:\n",
        "\n",
        "Accepts the activation map volume output by the pooling layer.\n",
        "Generates a 1D vector.\n",
        "Has a weight matrix associated with it for size matching.\n",
        "Multilayer Perceptron (MLP) Function:\n",
        "\n",
        "Accepts a vector, the number of hidden layers, the size of each hidden layer, an activation function, and the size of the output layer.\n",
        "Generates an output vector.\n",
        "Can generate the output with or without applying the softmax function to the output layer.\n",
        "Feed-forward Path (CNN Architecture):\n",
        "\n",
        "Combines the functions to create a CNN with a specific architecture.\n",
        "The architecture includes convolution layers, pooling layers, flattening, and MLP layers.\n",
        "Accepts an input image and outputs a vector.\n",
        "Analysis and Visualization:\n",
        "\n",
        "Display output vectors for images from each class.\n",
        "Analyze trends in the output vectors.\n",
        "Visualize the bottleneck layer (output of the flattening layer) using built-in t-SNE plots.\n",
        "Choose three images per class for t-SNE visualization.\n",
        "What's Implemented in the Code:\n",
        "\n",
        "Convolution Function:\n",
        "\n",
        "A basic convolution function has been implemented, but it may need further refinement to handle multi-channels and kernel volumes.\n",
        "Pooling Function:\n",
        "\n",
        "A basic pooling function has been implemented for 2D data.\n",
        "Convolution Layer Function:\n",
        "\n",
        "The code defines a function to perform convolution on a volume using a set of kernels.\n",
        "Pooling Layer Function:\n",
        "\n",
        "A function for pooling on a volume has been defined.\n",
        "Flattening Function:\n",
        "\n",
        "A basic flattening function has been provided.\n",
        "Multilayer Perceptron (MLP) Function:\n",
        "\n",
        "A simple feedforward MLP function is implemented but might need more layers and customization for your specific requirements.\n",
        "CIFAR-10 Data Loading:\n",
        "\n",
        "The code loads and preprocesses the CIFAR-10 dataset from a Google Drive link.\n",
        "Main Code:\n",
        "\n",
        "The main code provides placeholders for the CNN architecture, displaying output vectors, and t-SNE visualization."
      ],
      "metadata": {
        "id": "-BX-sGmK1cKh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "bHgu7eueEKPB",
        "outputId": "89b6a96d-f78f-44e7-af89-dd3e22c53bf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the PReLU activation function\n",
        "def prelu(x, alpha):\n",
        "    return np.maximum(0, x) + alpha * np.minimum(0, x)\n",
        "\n",
        "# Define the convolution function with PReLU activation\n",
        "def custom_convolution(input_image, filter_kernel, stride, padding, alpha):\n",
        "    # Apply padding if specified\n",
        "    if padding > 0:\n",
        "        input_image = np.pad(input_image, ((padding, padding), (padding, padding), (0, 0)), mode='constant')\n",
        "\n",
        "    # Get dimensions of input and kernel\n",
        "    input_height, input_width, input_channels = input_image.shape\n",
        "    kernel_height, kernel_width, kernel_channels = filter_kernel.shape\n",
        "\n",
        "    # Calculate output dimensions\n",
        "    output_height = int((input_height - kernel_height) / stride) + 1\n",
        "    output_width = int((input_width - kernel_width) / stride) + 1\n",
        "\n",
        "    # Initialize the output activation map\n",
        "    output_activation = np.zeros((output_height, output_width, kernel_channels))\n",
        "\n",
        "    # Perform convolution and apply PReLU activation\n",
        "    for i in range(0, input_height - kernel_height + 1, stride):\n",
        "        for j in range(0, input_width - kernel_width + 1, stride):\n",
        "            for c in range(kernel_channels):\n",
        "                convolution_result = np.sum(input_image[i:i+kernel_height, j:j+kernel_width, :] * filter_kernel[:, :, c])\n",
        "                output_activation[i, j, c] = prelu(convolution_result, alpha[c])\n",
        "\n",
        "    return output_activation\n",
        "\n",
        "# Example usage with learnable alphas:\n",
        "if __name__ == \"__main__\":\n",
        "    # Load an example image and kernel (replace with your own data)\n",
        "    input_image = np.random.rand(10, 10, 3)  # Replace with your input image\n",
        "    filter_kernel = np.random.rand(3, 3, 3)  # Replace with your filter kernel\n",
        "\n",
        "    # Define parameters\n",
        "    stride = 1\n",
        "    padding = 1\n",
        "\n",
        "    # Initialize learnable alpha parameters\n",
        "    num_channels = filter_kernel.shape[2]\n",
        "    alphas = np.random.rand(num_channels)  # Initialize with random values\n",
        "\n",
        "    # Perform convolution with PReLU activation\n",
        "    output_activation = custom_convolution(input_image, filter_kernel, stride, padding, alphas)\n",
        "\n",
        "    # Display the input image, filter kernel, and output activation map\n",
        "    plt.subplot(131)\n",
        "    plt.imshow(input_image)\n",
        "    plt.title(\"Input Image\")\n",
        "\n",
        "    plt.subplot(132)\n",
        "    plt.imshow(filter_kernel)\n",
        "    plt.title(\"Filter Kernel\")\n",
        "\n",
        "    plt.subplot(133)\n",
        "    plt.imshow(output_activation)\n",
        "    plt.title(\"Output Activation Map\")\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tarfile\n",
        "import urllib.request\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to download and extract the CIFAR-10 dataset\n",
        "def download_and_extract_cifar10():\n",
        "    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "    file_name = \"cifar-10-python.tar.gz\"\n",
        "\n",
        "    if not os.path.exists(file_name):\n",
        "        print(\"Downloading CIFAR-10 dataset...\")\n",
        "        urllib.request.urlretrieve(url, file_name)\n",
        "\n",
        "    # Extract the dataset\n",
        "    with tarfile.open(file_name, 'r:gz') as tar:\n",
        "        tar.extractall()\n",
        "    print(\"CIFAR-10 dataset extracted.\")\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "def load_cifar10_data(file_path):\n",
        "    with open(file_path, 'rb') as fo:\n",
        "        data = pickle.load(fo, encoding='bytes')\n",
        "    return data\n",
        "\n",
        "# Define the PReLU activation function\n",
        "def prelu(x, alpha):\n",
        "    return np.maximum(0, x) + alpha * np.minimum(0, x)\n",
        "\n",
        "# Define the convolution function with PReLU activation\n",
        "def custom_convolution(input_image, filter_kernel, stride, padding, alpha):\n",
        "    # Rest of your custom convolution code\n",
        "\n",
        " if __name__ == \"__main__\":\n",
        "    # Download and extract the CIFAR-10 dataset\n",
        "    download_and_extract_cifar10()\n",
        "\n",
        "    # Load CIFAR-10 dataset\n",
        "    data_batch = 1  # Specify the data batch you want to load\n",
        "    data = load_cifar10_data(f'cifar-10-batches-py/data_batch_{data_batch}')\n",
        "\n",
        "    # Assuming you have loaded the CIFAR-10 image and kernel as NumPy arrays\n",
        "    input_image = data['data'][0].reshape(32, 32, 3)  # Replace with your CIFAR-10 image\n",
        "    filter_kernel = np.random.rand(3, 3, 3)  # Replace with your filter kernel\n",
        "\n",
        "    # Define parameters\n",
        "    stride = 1\n",
        "    padding = 1\n",
        "\n",
        "    # Initialize learnable alpha parameters\n",
        "    num_channels = filter_kernel.shape[2]\n",
        "    alphas = np.random.rand(num_channels)  # Initialize with random values\n",
        "\n",
        "    # Perform convolution with PReLU activation\n",
        "    output_activation = custom_convolution(input_image, filter_kernel, stride, padding, alphas)\n",
        "\n",
        "    # Display the input image, filter kernel, and output activation map\n",
        "    plt.subplot(131)\n",
        "    plt.imshow(input_image)\n",
        "    plt.title(\"Input Image\")\n",
        "\n",
        "    plt.subplot(132)\n",
        "    plt.imshow(filter_kernel)\n",
        "    plt.title(\"Filter Kernel\")\n",
        "\n",
        "    plt.subplot(133)\n",
        "    plt.imshow(output_activation)\n",
        "    plt.title(\"Output Activation Map\")\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "IQ0QZfivpG6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the PReLU activation function\n",
        "def prelu(x, alpha):\n",
        "    return np.maximum(0, x) + alpha * np.minimum(0, x)\n",
        "\n",
        "# Define the convolution function with PReLU activation\n",
        "def custom_convolution(input_image, filter_kernel, stride, padding, alpha):\n",
        "    # Implement your convolution function here\n",
        "    pass\n",
        "\n",
        "# Define the pooling function (e.g., max pooling)\n",
        "def pooling(input_activation, stride):\n",
        "    # Implement your pooling function here\n",
        "    pass\n",
        "\n",
        "# Define the flattening function\n",
        "def flatten(input_activation):\n",
        "    return input_activation.flatten()\n",
        "\n",
        "# Define the fully connected (MLP) layer\n",
        "def mlp(input_vector, hidden_layers, hidden_layer_size, output_size, activation_function, softmax=False):\n",
        "    # Implement your MLP function here\n",
        "    pass\n",
        "\n",
        "# Task 7: Implement the CNN architecture as described\n",
        "def cnn_architecture(input_image):\n",
        "    # Convolution layer with 16 kernels of size 3x3x3 and sigmoid activation\n",
        "    kernel1 = np.random.rand(3, 3, 3, 16)\n",
        "    conv1 = custom_convolution(input_image, kernel1, stride=1, padding=0, alpha=None)\n",
        "    activation1 = 1 / (1 + np.exp(-conv1))  # Sigmoid activation\n",
        "\n",
        "    # Max pooling layer of size 2x2 with a stride of 2\n",
        "    pool1 = pooling(activation1, stride=2)\n",
        "\n",
        "    # Convolution layer with 8 kernels of size 3x3x16 and sigmoid activation\n",
        "    kernel2 = np.random.rand(3, 3, 16, 8)\n",
        "    conv2 = custom_convolution(pool1, kernel2, stride=1, padding=0, alpha=None)\n",
        "    activation2 = 1 / (1 + np.exp(-conv2))  # Sigmoid activation\n",
        "\n",
        "    # Max pooling layer of size 2x2 with a stride of 2\n",
        "    pool2 = pooling(activation2, stride=2)\n",
        "\n",
        "    # Flattening layer\n",
        "    flattened = flatten(pool2)\n",
        "\n",
        "    # MLP with one hidden layer, sigmoid activation\n",
        "    mlp_output = mlp(flattened, hidden_layers=1, hidden_layer_size=128, output_size=10, activation_function=prelu)\n",
        "\n",
        "    return mlp_output\n",
        "\n",
        "# Task 8: Visualize the output vectors and tSNE plots\n",
        "\n",
        "if __name__ == \"__main\":\n",
        "    # Create a random input image for testing\n",
        "    input_image = np.random.rand(32, 32, 3)\n",
        "\n",
        "    # Run the CNN architecture\n",
        "    output_vector = cnn_architecture(input_image)\n",
        "\n",
        "    print(\"Output Vector:\")\n",
        "    print(output_vector)\n"
      ],
      "metadata": {
        "id": "RR_XMqfprsop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy tensorflow scikit-learn requests\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QxigR4AuRug",
        "outputId": "53cc4d5e-78f2-4fb9-e243-273e1f981605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolution function:"
      ],
      "metadata": {
        "id": "gWKqZckRvcMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convolution(image, kernel, stride, padding, activation_fn):\n",
        "    # Apply padding to the input image if required\n",
        "    if padding > 0:\n",
        "        image = np.pad(image, ((padding, padding), (padding, padding), (0, 0)), mode='constant')\n",
        "\n",
        "    # Implement convolution logic with the given kernel, stride, and activation function\n",
        "    # Convolution result is stored in output_activation\n",
        "    output_activation = np.zeros((new_height, new_width, num_channels))\n",
        "\n",
        "    # Display input image, filter kernel, and output activation map\n",
        "    plt.figure(figsize=(6, 2))\n",
        "    plt.subplot(131)\n",
        "    plt.imshow(image)\n",
        "    plt.title(\"Input Image\")\n",
        "    plt.subplot(132)\n",
        "    plt.imshow(kernel)\n",
        "    plt.title(\"Filter Kernel\")\n",
        "    plt.subplot(133)\n",
        "    plt.imshow(output_activation)\n",
        "    plt.title(\"Output Activation Map\")\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "a0Xz3I6vvZFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pooling function:"
      ],
      "metadata": {
        "id": "H1znb_lPvneV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pooling(activation_map, pool_fn, stride):\n",
        "    # Implement pooling logic\n",
        "    # Pooling result is stored in pooled_activation\n",
        "    pooled_activation = np.zeros((new_height, new_width, num_channels))\n",
        "\n",
        "    # Display input activation map and pooled output\n",
        "    plt.figure(figsize=(6, 2))\n",
        "    plt.subplot(121)\n",
        "    plt.imshow(activation_map)\n",
        "    plt.title(\"Input Activation Map\")\n",
        "    plt.subplot(122)\n",
        "    plt.imshow(pooled_activation)\n",
        "    plt.title(\"Pooled Output\")\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "1JikLFhsvqfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolution layer function"
      ],
      "metadata": {
        "id": "BfG-x9RYvzNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convolution_layer(volume, kernels, stride, padding, activation_fn):\n",
        "    # Iterate through the kernels and apply convolution\n",
        "    activation_maps = []\n",
        "    for kernel in kernels:\n",
        "        activation_map = convolution(volume, kernel, stride, padding, activation_fn)\n",
        "        activation_maps.append(activation_map)\n",
        "\n",
        "    # Display input volume, filter kernels, and output activation maps\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(131)\n",
        "    plt.imshow(volume)\n",
        "    plt.title(\"Input Volume\")\n",
        "    plt.subplot(132)\n",
        "    plt.imshow(kernels[0])\n",
        "    plt.title(\"Filter Kernels\")\n",
        "    plt.subplot(133)\n",
        "    plt.imshow(activation_maps[0])\n",
        "    plt.title(\"Output Activation Maps\")\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "hMgGkbybv2lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pooling layer function:"
      ],
      "metadata": {
        "id": "1rZn4x1ov8mR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pooling_layer(activation_volume, pool_fn, stride):\n",
        "    # Iterate through activation maps and apply pooling\n",
        "    pooled_activation_maps = []\n",
        "    for activation_map in activation_volume:\n",
        "        pooled_activation_map = pooling(activation_map, pool_fn, stride)\n",
        "        pooled_activation_maps.append(pooled_activation_map)\n",
        "\n",
        "    # Display input activation volume and pooled output\n",
        "    plt.figure(figsize=(6, 2))\n",
        "    plt.subplot(121)\n",
        "    plt.imshow(activation_volume[0])\n",
        "    plt.title(\"Input Activation Volume\")\n",
        "    plt.subplot(122)\n",
        "    plt.imshow(pooled_activation_maps[0])\n",
        "    plt.title(\"Pooled Output\")\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "TCHY8kAbv9Pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flattening (unraveling) function:"
      ],
      "metadata": {
        "id": "i1xmMDnOwEQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten(activation_map_volume, weight_matrix):\n",
        "    # Implement flattening logic\n",
        "    flattened_vector = activation_map_volume.flatten()\n",
        "    return np.dot(flattened_vector, weight_matrix)\n"
      ],
      "metadata": {
        "id": "gtpHWTGVwG3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multilayer Perceptron (MLP) function:"
      ],
      "metadata": {
        "id": "XqO2C_rKwKIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mlp(input_vector, num_hidden_layers, hidden_layer_size, activation_fn, output_size, use_softmax):\n",
        "    # Implement MLP logic with specified layers, sizes, and activation functions\n",
        "    # Apply softmax if specified\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "6rEw9vsHwLWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For loading the CIFAR-10 dataset, you can use a library like torchvision if you're using PyTorch or load it directly from the dataset files.\n",
        "\n",
        "For t-SNE visualization, you can use the scikit-learn library as follows:"
      ],
      "metadata": {
        "id": "JAupOnl2wRz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Prepare the data for t-SNE\n",
        "bottleneck_layer_data = []  # Add bottleneck layer data for multiple images\n",
        "labels = []  # Add labels for each image\n",
        "\n",
        "# Perform t-SNE dimensionality reduction\n",
        "tsne = TSNE(n_components=2, perplexity=30, n_iter=300)\n",
        "tsne_results = tsne.fit_transform(bottleneck_layer_data)\n",
        "\n",
        "# Visualize the t-SNE results\n",
        "plt.scatter(tsne_results[:, 0], tsne_results[:, 1, c=labels)\n",
        "plt.title(\"t-SNE Visualization of Bottleneck Layer\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Rp1rTUKZwU5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main code would involve loading CIFAR-10 images, setting up your CNN architecture, and running the CNN forward pass using the cnn_forward function"
      ],
      "metadata": {
        "id": "z9Hasl7zwb5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "import tarfile\n",
        "import pickle\n",
        "\n",
        "# Function to load CIFAR-10 batch\n",
        "def load_batch(file_path):\n",
        "    with open(file_path, 'rb') as fo:\n",
        "        data_dict = pickle.load(fo, encoding='bytes')\n",
        "    return data_dict\n",
        "\n",
        "# Load and preprocess the CIFAR-10 dataset\n",
        "def load_cifar10_data(data_dir):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for i in range(1, 6):\n",
        "        batch = load_batch(data_dir + f\"/cifar-10-batches-py/data_batch_{i}\")\n",
        "        data.append(batch[b'data'])\n",
        "        labels.extend(batch[b'labels'])\n",
        "\n",
        "    X_train = np.concatenate(data)\n",
        "    X_train = X_train.reshape((len(X_train), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
        "    y_train = np.array(labels)\n",
        "\n",
        "    # Normalize the data\n",
        "    X_train = X_train / 255.0\n",
        "\n",
        "    return X_train, y_train\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "data_dir = \"cifar-10-data\"\n",
        "\n",
        "# Load and preprocess the CIFAR-10 dataset\n",
        "X_train, y_train = load_cifar10_data(data_dir)\n",
        "\n",
        "# Simple CNN architecture using TensorFlow\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model (you may need more epochs and data)\n",
        "model.fit(X_train, y_train, epochs=5)\n",
        "\n",
        "# 8a. Select one image from each class and display output vectors\n",
        "# You need to implement this based on the trained model\n",
        "\n",
        "# 8b. Visualize bottleneck layer using t-SNE\n",
        "bottleneck_layer_model = tf.keras.Model(inputs=model.input,\n",
        "                                       outputs=model.layers[-2].output)\n",
        "\n",
        "# Prepare data for t-SNE visualization\n",
        "selected_images = X_train[:100]  # Select a subset of the data for t-SNE visualization\n",
        "bottleneck_layer_data = bottleneck_layer_model.predict(selected_images)\n",
        "\n",
        "# Perform t-SNE dimensionality reduction\n",
        "tsne = TSNE(n_components=2, perplexity=30, n_iter=300)\n",
        "tsne_results = tsne.fit_transform(bottleneck_layer_data)\n",
        "\n",
        "# Visualize the t-SNE results\n",
        "plt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=y_train[:100])\n",
        "plt.title(\"t-SNE Visualization of Bottleneck Layer\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "L242luj2xUNF",
        "outputId": "25680e84-7c41-4c0f-9903-e372f458417b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7bc10e462833>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Load and preprocess the CIFAR-10 dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_cifar10_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Simple CNN architecture using TensorFlow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-7bc10e462833>\u001b[0m in \u001b[0;36mload_cifar10_data\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf\"/cifar-10-batches-py/data_batch_{i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mb'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mb'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-7bc10e462833>\u001b[0m in \u001b[0;36mload_batch\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Function to load CIFAR-10 batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mdata_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bytes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cifar-10-data/cifar-10-batches-py/data_batch_1'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure that the \"cifar-10-data\" directory exists\n",
        "import os\n",
        "\n",
        "data_dir = \"cifar-10-data\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(data_dir)\n",
        "\n",
        "# Upload the \"cifar-10-python.tar.gz\" file using the Google Colab file upload feature\n",
        "\n",
        "# Extract the dataset\n",
        "with tarfile.open(\"cifar-10-python.tar.gz\", 'r:gz') as tar:\n",
        "    tar.extractall(path=data_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "5bhtFjXxx8vI",
        "outputId": "d5106b88-63ea-460f-ca0f-546a29ccf2fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "EOFError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6e6f9dde853a>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Extract the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cifar-10-python.tar.gz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r:gz'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/tarfile.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members, numeric_owner, filter)\u001b[0m\n\u001b[1;32m   2255\u001b[0m                 \u001b[0;31m# extracting contents can reset mtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2256\u001b[0m                 \u001b[0mdirectories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2257\u001b[0;31m             self._extract_one(tarinfo, path, set_attrs=not tarinfo.isdir(),\n\u001b[0m\u001b[1;32m   2258\u001b[0m                               numeric_owner=numeric_owner)\n\u001b[1;32m   2259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/tarfile.py\u001b[0m in \u001b[0;36m_extract_one\u001b[0;34m(self, tarinfo, path, set_attrs, numeric_owner)\u001b[0m\n\u001b[1;32m   2318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2320\u001b[0;31m             self._extract_member(tarinfo, os.path.join(path, tarinfo.name),\n\u001b[0m\u001b[1;32m   2321\u001b[0m                                  \u001b[0mset_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset_attrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m                                  numeric_owner=numeric_owner)\n",
            "\u001b[0;32m/usr/lib/python3.10/tarfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, tarinfo, targetpath, set_attrs, numeric_owner)\u001b[0m\n\u001b[1;32m   2401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misreg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2403\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2404\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2405\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/tarfile.py\u001b[0m in \u001b[0;36mmakefile\u001b[0;34m(self, tarinfo, targetpath)\u001b[0m\n\u001b[1;32m   2454\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2455\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2456\u001b[0;31m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReadError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2458\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmakeunknown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/tarfile.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(src, dst, length, exception, bufsize)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremainder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unexpected end of data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m                 raise EOFError(\"Compressed file ended before the \"\n\u001b[0m\u001b[1;32m    508\u001b[0m                                \"end-of-stream marker was reached\")\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEOFError\u001b[0m: Compressed file ended before the end-of-stream marker was reached"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "import pickle\n",
        "import os\n",
        "import requests\n",
        "import tarfile\n",
        "\n",
        "# Define activation functions\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "# Function to load CIFAR-10 dataset from Google Drive link\n",
        "def load_cifar10_data(data_dir):\n",
        "    # Download and extract the CIFAR-10 dataset from the Google Drive link\n",
        "    file_id = '1NFP1QOAPidBR8v233UAmnQrZ7PUVSBos'\n",
        "    url = f'https://drive.google.com/uc?id={file_id}'\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        with open('cifar-10-python.tar.gz', 'wb') as f:\n",
        "            f.write(response.content)\n",
        "\n",
        "        with tarfile.open('cifar-10-python.tar.gz', 'r:gz') as tar:\n",
        "            tar.extractall(data_dir)\n",
        "\n",
        "    # Load and preprocess the CIFAR-10 data\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for batch in range(1, 6):\n",
        "        with open(os.path.join(data_dir, f'cifar-10-batches-py/data_batch_{batch}'), 'rb') as fo:\n",
        "            batch_data = pickle.load(fo, encoding='bytes')\n",
        "            data.append(batch_data[b'data'])\n",
        "            labels += batch_data[b'labels']\n",
        "\n",
        "    X_train = np.vstack(data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1).astype(float) / 255.0\n",
        "    y_train = np.array(labels)\n",
        "\n",
        "    return X_train, y_train\n",
        "\n",
        "# 1. Convolution function\n",
        "def convolution(image, kernel, stride, padding, activation_fn):\n",
        "    h, w, c = image.shape\n",
        "    kh, kw, kc = kernel.shape\n",
        "    if padding > 0:\n",
        "        image = np.pad(image, ((padding, padding), (padding, padding), (0, 0)), mode='constant')\n",
        "        h, w, c = image.shape\n",
        "\n",
        "    oh = (h - kh) // stride + 1\n",
        "    ow = (w - kw) // stride + 1\n",
        "\n",
        "    output = np.zeros((oh, ow))\n",
        "    for i in range(0, h - kh + 1, stride):\n",
        "        for j in range(0, w - kw + 1, stride):\n",
        "            receptive_field = image[i:i+kh, j:j+kw, :]\n",
        "            activation = activation_fn(np.sum(receptive_field * kernel))\n",
        "            output[i // stride, j // stride] = activation\n",
        "    return output\n",
        "\n",
        "# 2. Pooling function\n",
        "def pooling(activation_map, pool_fn, stride):\n",
        "    h, w = activation_map.shape\n",
        "    oh = h // stride\n",
        "    ow = w // stride\n",
        "\n",
        "    output = np.zeros((oh, ow))\n",
        "    for i in range(oh):\n",
        "        for j in range(ow):\n",
        "            region = activation_map[i*stride:(i+1)*stride, j*stride:(j+1)*stride]\n",
        "            output[i, j] = pool_fn(region)\n",
        "    return output\n",
        "\n",
        "# 3. Convolution layer function\n",
        "def convolution_layer(volume, kernels, stride, padding, activation_fn):\n",
        "    oh, ow, num_kernels = kernels.shape[0], kernels.shape[1], kernels.shape[2]\n",
        "    activation_volume = np.zeros((oh, ow, num_kernels))\n",
        "    for i in range(num_kernels):\n",
        "        activation_volume[:, :, i] = convolution(volume, kernels[:, :, i, :], stride, padding, activation_fn)\n",
        "    return activation_volume\n",
        "\n",
        "# 4. Pooling layer function\n",
        "def pooling_layer(activation_volume, pool_fn, stride):\n",
        "    oh, ow, num_kernels = activation_volume.shape[0], activation_volume.shape[1], activation_volume.shape[2]\n",
        "    pooled_volume = np.zeros((oh // stride, ow // stride, num_kernels))\n",
        "    for i in range(num_kernels):\n",
        "        pooled_volume[:, :, i] = pooling(activation_volume[:, :, i], pool_fn, stride)\n",
        "    return pooled_volume\n",
        "\n",
        "# 5. Flattening (unraveling) function\n",
        "def flatten(activation_map_volume):\n",
        "    return activation_map_volume.flatten()\n",
        "\n",
        "# 6. Multilayer Perceptron (MLP) function\n",
        "def mlp(input_vector, num_hidden_layers, hidden_layer_size, activation_fn, output_size, use_softmax):\n",
        "    input_size = input_vector.shape[0]\n",
        "    layers = [input_vector]\n",
        "\n",
        "    for _ in range(num_hidden_layers):\n",
        "        weights = np.random.randn(input_size, hidden_layer_size)\n",
        "        biases = np.zeros((1, hidden_layer_size))\n",
        "        layer_output = activation_fn(np.dot(layers[-1], weights) + biases)\n",
        "        layers.append(layer_output)\n",
        "\n",
        "    weights = np.random.randn(hidden_layer_size, output_size)\n",
        "    biases = np.zeros((1, output_size))\n",
        "    output = np.dot(layers[-1], weights) + biases\n",
        "\n",
        "    if use_softmax:\n",
        "        output = np.exp(output) / np.sum(np.exp(output), axis=1, keepdims=True)\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "# 7. CNN Architecture\n",
        "def cnn_architecture(X):\n",
        "    # Implement the CNN architecture as specified in the assignment\n",
        "    pass\n",
        "\n",
        "# 8a. Display output vectors for images from each class\n",
        "def display_output_vectors(images, labels):\n",
        "    # Implement displaying output vectors for selected images\n",
        "    pass\n",
        "\n",
        "# 8b. Visualize bottleneck layer using t-SNE\n",
        "def visualize_bottleneck_layer(images, labels):\n",
        "    # Implement t-SNE visualization of the bottleneck layer\n",
        "    pass\n",
        "\n",
        "# Main code\n",
        "if __name__ == \"__main__\":\n",
        "    # Step 2: Load and preprocess the CIFAR-10 dataset\n",
        "    data_dir = \"cifar-10-data\"\n",
        "    if not os.path.exists(data_dir):\n",
        "        os.mkdir(data_dir)\n",
        "\n",
        "    X_train, y_train = load_cifar10_data(data_dir)\n",
        "\n",
        "    # Step 7: CNN Architecture\n",
        "    output_vectors = cnn_architecture(X_train)\n",
        "\n",
        "    # Step 8a: Display output vectors for images from each class\n",
        "    # Select one image from each class and run the CNN to get output vectors\n",
        "\n",
        "    # Step 8b: Visualize bottleneck layer using t-SNE\n",
        "    # Implement t-SNE visualization of the bottleneck layer\n",
        "\n"
      ],
      "metadata": {
        "id": "reGH2Mcm0DhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code I provided above is a Python codefor a Convolutional Neural Network (CNN) architecture based on the assignment requirements. I'll explain the code in detail:\n",
        "\n",
        "Importing Libraries: The code starts by importing necessary libraries such as NumPy for numerical operations, Matplotlib for visualization, scikit-learn for t-SNE, and other standard Python libraries.\n",
        "\n",
        "Activation Functions: Two activation functions, sigmoid and ReLU, are defined. These are the functions that introduce non-linearity to the network.\n",
        "\n",
        "Load CIFAR-10 Dataset: The load_cifar10_data function is responsible for downloading and preprocessing the CIFAR-10 dataset. It downloads the dataset from a Google Drive link, extracts it, and loads the training data and labels. The dataset is divided into batches, and images are reshaped and normalized.\n",
        "\n",
        "Convolution Function: The convolution function takes an image, a filter (kernel), stride, padding, and an activation function as input. It performs convolution on the image using the filter with the specified stride and padding, and then applies the activation function to the resulting activation map.\n",
        "\n",
        "Pooling Function: The pooling function takes an activation map, a pooling function, and stride as input. It performs pooling on the activation map with the specified pooling function and stride.\n",
        "\n",
        "Convolution Layer Function: The convolution_layer function takes a volume (input image or activation maps), a set of filter kernels, stride, padding, and an activation function as input. It applies convolution to the input volume using each kernel, and the output is an activation volume.\n",
        "\n",
        "Pooling Layer Function: The pooling_layer function takes an activation map volume, a pooling function, and stride as input. It performs pooling on each activation map in the volume and returns a pooled volume.\n",
        "\n",
        "Flattening Function: The flatten function takes an activation map volume as input and converts it into a 1D vector. This is necessary before passing data to a fully connected MLP layer.\n",
        "\n",
        "Multilayer Perceptron (MLP) Function: The mlp function implements a basic feedforward neural network (fully connected layer). It takes an input vector, the number of hidden layers, size of each hidden layer, an activation function, output size, and a flag for using softmax. It generates the output of the MLP, optionally applying softmax if specified.\n",
        "\n",
        "CNN Architecture: The cnn_architecture function is where you define the CNN architecture as specified in the assignment. This includes convolution layers, pooling layers, flattening, and MLP layers. You need to specify the number of layers, kernel sizes, activation functions, and other parameters according to your assignment's requirements.\n",
        "\n",
        "Display Output Vectors: The display_output_vectors function is supposed to display output vectors for one image from each class. However, this function is not implemented in the template, and you need to complete it based on your needs.\n",
        "\n",
        "Visualize Bottleneck Layer with t-SNE: The visualize_bottleneck_layer function is intended to visualize the bottleneck layer using t-SNE for discriminability analysis. It is also left unimplemented in the template.\n",
        "\n",
        "Main Code: In the main code section, the script loads the CIFAR-10 dataset, runs the CNN architecture, and has placeholders for displaying output vectors and visualizing the bottleneck layer.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kzXOmtar0fnY"
      }
    }
  ]
}